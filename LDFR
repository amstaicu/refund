#' Longitudinal Dynamic Functional Regression
#'
#'  It implements longitudinal dynamic functional regression (Islam et al. (2018)) model for longitudinally observed scalar responses 
#'  and functional predictors, where responses belong to an exponential family distribution. The methodology accommodates 
#'  single/multiple functional predictors with or without single/multiple scalar predictors. The current version fits the model using 
#'  three different covariance structures for responses : (1) subject-specific random intercept, (2) subject-specific random intercept 
#'  and slope, (3) random block and subject-specific intercept effect. The method uses orthonormal eigenbases obtained from the 
#'  covariance operator of a functional predictor by FPCA to model both functional measurements and bivariate coefficient function.
#'  Using orthonormality of bases, it casts the model into a time-varying coefficient model where scores play the role of regressors. 
#'  The estimation of scores is done in 2-steps: (1) using numerical integration, it obtains  pseudo scores at the observed time points
#'  or visit times and (2) applying another FPCA on the covariance of pseudo scores and predicting scores for all visit times using 
#'  Yao et al. (2005). Parameters are estimated using a mixed model framework.
#'
#' @section Details :
#'   LDFR model can be fitted with either \command{lme} function from \command{nlme}, \command{gamm4} or \command{gam} function from 
#'   \command{mgcv} \command{R} package. We illustarte the method using the \command{bam} function currently.
#'
#'@param I        total number of subjects
#'@param IW       total number of (new + existing) subjects; new subject is (IW - I). Note that
#'                profile information must be available for each IW. Default is NULL
#'@param subj     subject identification (id) for each response; e.g., (1, 1, 1, 2, 2, 3, 3, ...).
#'                If IW is NOT null, then ID is the vector of subject  for both existing and new
#'                subjects. Otherwise, this contains id's only for existing subjects
#'@param group    Group identification if there is a block effect needed. Default is NULL
#'@param Tij      sparse/dense time-points corresponding to each response; if IW is NOT null,
#'                Tij is the vector of actual visit times at which profiles are recorded for both
#'                existing and new subjects. Otherwise, Tij contains time-points only for
#'                existing subjects. Assume compact set [0,1] for its domain
#'@param Yij      scalar responses at observed Tij's for existing subjects
#'@param funcs    a list of  observed functional predictors; if IW is NOT null then funcs is
#'                row-concatenation of profiles for new and existing subjects in, say funcs[[1]].
#'                If IW is null, then funcs[[1]] consists of profiles only for existing subjects
#'@param covariate scalar covariate; default is NULL
#'@param covariate.type Whether scalar covariate information varies at each time; e.g., gender
#'                remains constant for all time points; default is "Constant". In such case, it is
#'                possible to impute covariate information at unobserved time points and
#'                obtain full response trajectory (if asked) adjusting for it. Varying scalar
#'                covariate ("Varying) can also be used. If full information all all time points is not available,
#'                we proceed to obtain trajectory without it
#'@param nbf      number of basis functions used to represent temporal non-parametric smooth functions
#'@param method   smoothing parameter selection criteria; default is REML
#'@param pve      pre-specified proportion of variance explained; default value is 0.95
#'@param Yerror   type of dependence structure for responses; "CS" for subject-specific random
#'                intercept, "IS" for both subject-specific random intercept and slope, "CSG" for
#'                subject-specific random intercept and random group effect
#'@param family   exponential family distribution
#'@param pred.interval  Logical argument. Default is TRUE to generate prediction trajectory interval
#'@param alpha    level of significance at which prediction interval is desired; e.g. 0.01 or 0.05
#'@param plot     logical value; TRUE refers to plotting coefficient functions and prediction intervals; default is FALSE
#'@param subj.id  referring to observed subject id for which prediction trajectory needs to plot; default is NULL
#'@param subj.id.X referring to new subject id for which prediction trajectory needs to plot; default is NULL
#'
#'@return
#'  \item{fit}{a gam fitted object}
#'  \item{model_adequacy}{AIC, BIC, Rsq, and deviance explained for model selection}
#'  \item{fitted_vals}{predicted responses for observed time-points}
#'  \item{full_fitted_vals_obs}{predicted responses for all time-points}
#'  \item{full_fitted_vals_unobs}{predicted responses for all time-points for unobserved subject at population level}
#'  \item{error}{prediction error at observed time points for observed subjects}
#'  \item{npc}{number of fPCs}
#'  \item{phi}{empirical basis functions}
#'  \item{evalues}{empirical eigenvalues}
#'  \item{scores_hat}{time-varying coefficients for each k at observed time-points}
#'  \item{scores_hat_traj}{full trajectory of time-varying coefficients for each k}
#'  \item{scores_pseudo}{raw time-varying loadings}
#'  \item{ranef_intercept}{prediction of subject-specific random intercept effect}
#'  \item{ranef_slope}{prediction of subject-specific random slope effect if Yerror = "IS", otherwise NULL}
#'  \item{ranef_group}{prediction of random group effects}
#'  \item{Mean_X_obs}{mean of functional predictor for observed time points (visits)}
#'  \item{gamma}{estimates of smooth coefficient}
#'  \item{covariate_effect}{parameter estimates of scalar covariate(s)}
#'  \item{beta}{estimates of dynamic parameters}
#'  \item{beta0}{estimates of smooth intercept}
#'  \item{Bounds}{confidence interval for smooth estimates}
#'  \item{BoundYF}{prediction band for observed response trajectory}
#'  \item{BoundXF}{prediction band for unobserved response trajectory}
#'  \item{mFPCA}{fpca.face fitted object which primarily gives raw scores}
#'  \item{sFPCA}{fpca.sc fitted object which is used on estimating full trajectory of scores}
#'
#'  @author Md Nazmul Islam \email{mnislam@ncsu.edu}, Ana-Maria Staicu
#'  @export
#'
#'  @references Islam, Md Nazmul, Staicu, A.M., and Heugten, Eric-Van. Longitudinal Dynamic Functional Regression. Journal of Royal 
#'  Statistical Society, Series C (under revision)
#'
#' @import mgcv
#' @import Matrix
#' @import MASS
#' @import ggplot2
#' @import RColorBrewer
#' @import reshape2
#' @import refund
#'
#' @examples
#' \dontrun{
#'
#' ## ---------------------- Function to simulate data ----------------------- ##
#'
#' onesubj <- function (A, i, TT, ss, Yerror, delta){
#'  set.seed (A)
#'  J <- length(TT)
#'  SS <- length(ss)
#'  Si.i11 <- rnorm (1, mean = 0, sd = sqrt(3.5))
#'  Si.i12 <- rnorm (1, mean = 0, sd = sqrt(2))
#'  Si.i21 <- rnorm(1, mean = 0, sd = sqrt(3))
#'  Si.i22 <- rnorm(1, mean = 0, sd = sqrt(1.5))
#'  zetai1 <- Si.i11 * cos(2 * pi * TT) + Si.i12 *  sin(2 * pi * TT)
#'  zetai2 <- Si.i21 * cos(4 * pi * TT) + Si.i22 *  sin(4 * pi * TT)
#'  MU.Xi <- do.call(rbind, lapply(TT, function(cc) as.vector(1 + 2 * ss + 3 * cc + 4 * ss * cc)))
#'  phi1 <- sqrt(2) * cos (2 * pi * ss)
#'  phi2 <- sqrt(2) * sin (2 * pi * ss)
#'  true.alpha <- 7 * sin(3 * pi * TT)
#'  true.beta1  <- exp (- TT * delta)
#'  true.beta2 <- delta * TT * sin ( delta * TT)
#'
#'  ### ------------------------ defining true functional predictors ----------------------###
#'
#'  true.func.cov <- MU.Xi + do.call(rbind, lapply(zetai2, function (feb)
#'    feb * phi2)) + do.call(rbind, lapply(zetai1, function (jan) jan * phi1))
#'
#'  ### ----------------------- defining error structure for response -------------------- ###
#'  if (Yerror == "IS"){
#'    meanYij3 <- rep(0, J)
#'    Z <- cbind(1, TT)
#'    D <- matrix(c(1, 0.1, 0.1, 0.5), 2, 2)
#'    varYij3 <- (Z %*% D) %*% t(Z) + diag(0.5, J)
#'    Randi <-  mvrnorm(1, meanYij3, varYij3)
#'    blockid <- 0}
#'  else if (Yerror == "CS") {
#'    meanYij3 <- rep(0, J)
#'    varYij3 <- diag(0.5, J) + matrix(1, nrow = J, ncol = J)
#'    Randi <- mvrnorm(1, meanYij3, varYij3)
#'    blockid <- 0}
#'  else if (Yerror == "CSG"){
#'   gk <- rnorm(20, 1, 2)      # group effect
#'  meanYij3 <- rep(0, J)
#'  bid <- sample(1 : 20, 1)
#'  blockid <- rep(bid, J)      # block membership
#'  varYij3 <- diag(0.5, J) + matrix(1, nrow = J, ncol = J)
#'  Randi <- mvrnorm(1, meanYij3, varYij3) + rep(gk[bid], J)}
#'  rng <- max(TT) -  min(TT)
#'  au <- runif(1, 1, 6)
#'  cov <- rep(au, J)            # covariate
#'
#'  ### --------------------------------- Generating responses -------------------------- ###
#'  Yi.r <-  apply(true.func.cov, 1, function(v){mean(v * phi2) * rng }) * (true.beta2) +
#'    apply(true.func.cov, 1, function(v){mean(v * phi1 ) * rng }) * (true.beta1)  +
#'    true.alpha + cov * 0.5 + Randi
#'
#'  ### ---------------- defining error structure for observed predictors --------------- ###
#'  e1 <- rnorm(J, mean = 0, sd = sqrt(0.3))
#'  e2 <- rnorm(J, mean = 0, sd = sqrt(0.7))
#'  e3 <- matrix(rnorm(J * SS , mean = 0, sd = sqrt(1)), nrow = J, byrow = T)
#'  errorX <- do.call(rbind, lapply(e1, function (d) d * phi1)) + do.call(rbind,
#'                                      lapply(e2, function (d) d * phi2)) + e3
#'  obs.func.cov <- true.func.cov +  errorX
#'  data <- cbind(i = rep(i, J), Tij = TT, Yij = Yi.r, cov = cov, obs.func.cov = obs.func.cov,
#'  blockid = blockid)}
#'
#' ### ------------------ Sparse data set generated from full data set ------------------- ###
#' sparsefun <- function (A, i, TT, data){
#'  set.seed (A)
#'  J <- length(TT)
#'  mi <- sample(15 : 25, size = 1)
#'  ith <- sort (sample(1 : J, size = mi), decreasing = FALSE)
#'  ith.data <- data [which(data$i == i ), ]
#'  k1 <- ith.data [ith, ]
#'  k1}
#'
#' A = 10004              # seed number
#' TT <- seq(0, 1, length.out = 41)  # grid in t-direction
#' ss <- seq(0, 1, length.out = 101) # grid in s-direction
#' I <- 200               # existing subject
#' IW <- 300              # new subject + existing subject
#' delta <- NULL          # intensity at which predictor evolves over time
#'
#' ## --------------------------------------------------------------------------------------- ##
#' ## ------- Illustration : 1 Responses have compound-symmetric covariance structure ------- ##
#' ## ---- Here we have covariate information for both observed & new subjects -------------- ##
#'
#' dat.full <- data.frame(do.call(rbind, lapply(seq_len(IW), function(i)
#'                                onesubj (A = i + A, i, TT, ss, Yerror = "CS", delta = 5))))
#'
#' dat.obs <- do.call(rbind, lapply(seq_len(IW), function(i)
#'                                    sparsefun(A = i + A , i, TT, data = dat.full)))
#'
#' EX <- which(dat.obs[, 1] > I)
#' # EX is an indexing variable. First I-subjects are the observed subjects while the rest (IW - I)
#' # are new subjects for which responses are missing. We recover population-level full trajectory
#' # for this (IW -I) subjects.
#'
#' Yij <- dat.obs[- EX, 3]        # scalar response
#' subj <- dat.obs[, 1];          # subject identification
#' Tij <- dat.obs[, 2];           # visit times
#' funcs <- covariate <- list()
#' covariate[[1]] <- dat.obs[, 4] # scalar covariate
#' funcs[[1]] <- as.matrix(dat.obs [, c(5 : 105)]) # Functional predictor
#'
#' fit1 <- LDFR(I = I, IW = IW, subj = subj, group = NULL, Tij = Tij, Yij = Yij, funcs = funcs,
#'    covariate = covariate, covariate.type = "Constant", nbf = 15, method = "REML", pve = 0.95,
#'    Yerror = "CS", family = gaussian, pred.interval = TRUE, alpha = 0.05,
#'    plot = TRUE, subj.id = c(10, 50, 120, 190), subj.id.X = c(220, 290, 250, 280))
#'
#' ## -------------------------------------------------------------------------------------------- ##
#' ## --- Illustration : 2 Responses are generated using subject-specific intercept and slope. --- ##
#' ## ------------ Here we have only covariate information for observed subjects ----------------- ##
#'
#' dat.full <- data.frame(do.call(rbind, lapply(seq_len(I), function(i)
#'                                onesubj (A = i + A, i, TT, ss, Yerror = "IS", delta = 5))))
#'
#' dat.obs <- do.call(rbind, lapply(seq_len(I), function(i)
#'                                sparsefun(A = i + A , i, TT, data = dat.full)))
#'
#' Yij <- dat.obs[, 3]          # scalar response
#' subj <- dat.obs[, 1]          # subject identification
#' Tij <- dat.obs[, 2]           # visit times
#' funcs <- covariate <- list()
#' covariate[[1]] <- dat.obs[, 4]                      # scalar covariate
#' funcs[[1]] <- as.matrix(dat.obs [, c(5 : 105)])     # functional predictor
#'
#' fit2 <- LDFR(I = I, IW = NULL, subj = subj, group = NULL, Tij = Tij, Yij = Yij, funcs = funcs,
#'    covariate = covariate, covariate.type = "Constant", nbf = 15, method = "REML", pve = 0.95,
#'    Yerror = "IS", family = gaussian, pred.interval = TRUE, alpha = 0.05,
#'    plot = TRUE, subj.id = c(111, 77, 11, 44), subj.id.X = NULL)
#'
#'}  # Illustration ends
## ----------------------------------------------------------------------------------------- ##
## ----------------------------------------------------------------------------------------- ##

LDFR <- function(I, IW = NULL, subj, group = NULL, Tij, Yij, funcs, covariate = NULL, covariate.type = NULL,
                 nbf, method, pve, Yerror, family, pred.interval = TRUE, alpha, plot = FALSE, subj.id = NULL,
                 subj.id.X = NULL){
  
  ###------------------------ Sanity check ------------------------###
  
  if(is.list(funcs) == FALSE){
    stop("funcs needs to be in a list; e.g., funcs[[1]] corresponds to first functional predictor")
  }
  if(is.null(covariate) == FALSE && is.list(covariate) == FALSE){
    stop("covariate needs to be in a list; e.g., covariate[[1]] corresponds to first scalar covariate")
  }
  if(is.null(covariate) == FALSE && is.list(covariate) == TRUE){
    covariate.mat <-    do.call(cbind, lapply(seq_len(length(covariate)), function(ii) covariate[[ii]]))
  }
  if(is.null(IW) == TRUE){
    IW = I
  }
  
  ###------------------------  Extract data ------------------------###
  
  ID =  subj;
  ln <- length(Tij);
  TT <- sort(unique(Tij));
  J <- length(TT)
  if(is.null(group) == FALSE) {G <- length(unique(group))}
  IDF <- unlist(lapply(seq_len(IW), function(gh) rep(gh, J))) # ID generation for all visit times
  TijF <- rep(TT, IW)   # All visit times in domain
  allseq <- seq_len(IW * J)
  out_subj <- unlist(lapply(seq_len(IW), function(ii) allseq[which(IDF == ii)]
                            [match(Tij[which(subj == ii)], TT)]))
  # indexing variable that determines the positions of each response across existing subjects
  
  V <- unlist(lapply(seq_len(IW), function(ii) match(Tij[which(subj == ii)], TT)))
  # position of each response within each subject in the domain of time
  
  if(length(IW) != 0){
    freq <- unlist(lapply(seq_len(IW), function(ii) length(which(ID == ii))))
  }
  if(length(IW) == 0){
    freq <- unlist(lapply(seq_len(I), function(ii) length(which(ID == ii))))
  }
  
  ### -----  generating variables for ID and Time for all subjects at all J time-points ----- ###
  
  if(is.null(covariate) == FALSE &&  covariate.type == "Constant"){
    cov.obs.all <- matrix(0, nrow = (IW * J), ncol = ncol(covariate.mat))
    for(nn in 1 : ncol(covariate.mat)){
      cov.obs.all[, nn] <- unlist(lapply(seq_len(IW), function(ii)
        rep(covariate.mat[which(ID == ii)[1], nn], J)))}}
  
  if(is.null(covariate) == FALSE &&  covariate.type == "Varying" && nrow(covariate.mat) == (I * J)){
    print("CAUTION : Full response trajectory is based on functional predictor(s) only as scalar covariate
          information is missing at unobserved visit times.")
    cov.obs.all <- NULL}
  
  ### ------------------------ estimating mean function -------------------------------- ###
  
  obs.func.cov <- length.grid <- grid <- fbps.fit <- MU.X <- deM.X <- covsmooth <- phi.hat <-
    K.hat <- zetaw.hat <- mu <-  eigenvalues <- fit2 <- zetaw.hatE <- zetaw.hatF <- zetaw.hatN<-
    zetaw.hatX <-  fMU.X <- MU.gam <- list()
  
  for(n in 1  : length(funcs)){
    obs.func.cov <- funcs[[n]]
    length.grid[[n]] <- dim(obs.func.cov)[2]
    SS <-  length.grid[[n]]
    grid[[n]] <- seq(0, 1, length.out = length.grid[[n]]);
    ss <- grid[[n]]
    fbps.fit[[n]] <-  fbps(data = obs.func.cov, covariates = c(Tij, ss))
    muhat0 <- matrix(0, nrow = J, ncol = SS)
    muhat.dat <- do.call(rbind, lapply(seq_len(J), function(de){
      t1 <- TT[de]
      r1 <- as.vector(which(Tij == t1))[1]
      muhat0[de,] <- fbps.fit[[n]]$Yhat[r1, ]}))
    newmu.dat <- data.frame (y = as.vector(t(muhat.dat)), x1 = rep(ss, J), x2 = rep(TT, SS))
    MU.gam[[n]] <- gam (y ~ te(x1, x2, k = c(10, 5), bs = "cr"), data = newmu.dat, method = method)
    MU.gam.dat <- data.frame(x1 = rep(ss, ln), x2 = rep(Tij, SS) )
    MU.X[[n]] <- matrix(predict.gam(MU.gam[[n]], newdata = MU.gam.dat), nrow = ln, ncol = SS, byrow = T)
    
    ### -------------------- demeaning functional predictor ---------------------- ###
    
    deM.X[[n]] <- obs.func.cov - fbps.fit[[n]]$Yhat
    
    ### --------  finding the eigen-components of covariance  operator ----------- ###
    covsmooth[[n]] <- fpca.face (Y = deM.X[[n]], pve = pve, var =  TRUE)
    phi.mat <- covsmooth[[n]]$efunctions
    phi.hat[[n]] <- phi.mat * sqrt(SS)
    K.hat[[n]] <- covsmooth[[n]]$npc;
    
    zetaw.hat[[n]] <- covsmooth[[n]]$scores / sqrt (SS)
    mu[[n]] <- covsmooth[[n]]$mu
    eigenvalues[[n]] <- covsmooth[[n]]$evalues / SS
    eigenvalues[[n]][which(eigenvalues[[n]] < 0)] <- 0
    
    k1 <- all.equal (as.vector(do.call(rbind, lapply(seq_len(K.hat[[n]]), function(feb)
      sqrt(mean (length(ss) * phi.mat[, feb] ^ 2 ))))), rep(1, K.hat[[n]]))
    if(k1 != "TRUE") stop("L2 norm for eigenbases mismatches")
    
    ### ----------------- predicting the time-varying loadings (un)observed) -------------------- ###
    
    if(length(IW) == 0){IW <- I}    # implying no new subjects
    xi.hat0 <- list()
    for(k in seq_len(K.hat[[n]])){
      xihat0.vec <- zetaw.hat[[n]][, k]
      xi.hat0[[ k ]]<- t(sapply( seq_len(IW), function(i) {
        xi.subj <- matrix(nrow = 1, ncol = J)
        xi.subj[V[which(ID == i)]] <- xihat0.vec[which(ID == i)]
        return(xi.subj)
      }))}
    fit2[[n]] <- lapply(xi.hat0, function(a) try(fpca.sc(Y = a, pve = pve, var = TRUE)))
    xi.hat <- lapply(fit2[[n]], function(a) a$Yhat)
    zetaw.hatF[[n]] <- do.call(cbind, lapply(xi.hat, function(gg) as.vector(t(gg))))
    
    if(length(out_subj) == 1){
      if(nrow(zetaw.hatF[[n]]) != (I * J)){
        stop("Time-varying scores are not recovered for all visit times for each subject")}
    }else{
      if(nrow(zetaw.hatF[[n]]) != (IW * J))
        stop("Time-varying scores are not recovered for all visit times for each subject")}
  }
  
  ### ---- If IW == I (implying no new subjects and do analysis on the existing subjects ) ---- ###
  
  if(IW == I){
    Ind <- seq_len(dim(zetaw.hatF[[1]])[1])
    Index <- unlist(lapply(seq_len(IW), function(ui) Ind[which(IDF == ui)][V[which(ID == ui)]]))
    # index for time-points at which profiles are available
    for(n in 1  : length(funcs)){
      zetaw.hatN[[n]] <- do.call (cbind, lapply(xi.hat, function(gg) as.vector(t(gg))[Index]))
      zetaw.hatE[[n]] <- zetaw.hatF[[n]]}
    
    if(is.null(covariate) == FALSE){cov.obs <-  covariate.mat
    }else{cov.obs <- NULL}
    
    TijFN <- TijF; IDFN <- groupFN <- IDF; Yij <- Yij; Tij <- Tij; ID <- ID
    
    if(is.null(group) == FALSE){
      group <- group
      grpmember <- lapply(seq_len(IW), function(ii) group[which(ID == unique(ID)[ii])][1])
      for(ii in 1 : IW){
        groupFN[which(IDFN == unique(ID)[ii])] <- grpmember[[ii]]}}}
  
  ### -------------- If IW != I (implying there exists new subjects ------------- ###
  
  if(IW != I){
    index0 <- seq_len(I * J)
    index1 <-  out_subj[- which(ID > I)]
    index2 <- seq_len(IW * J)[- c(index0)]
    for(n in 1  : length(funcs)){
      zetaw.hatE[[n]] <- do.call (cbind, lapply ( xi.hat, function(gg) as.vector(t(gg))[index0]))
      # predicted scores for observed subjects at each time-points
      zetaw.hatN[[n]] <- do.call (cbind, lapply ( xi.hat, function(gg) as.vector(t(gg))[index1]))
      # predicted scores for observed subjects at observed time points
      zetaw.hatX[[n]] <- do.call (cbind, lapply ( xi.hat, function(gg) as.vector(t(gg))[index2]))
      # redicted scores for unobserved subjects at each time-points
    }
    
    Yij <- Yij; V <- V[-which(ID > I)]; Tij <- Tij[-which(ID > I)]
    
    if(is.null(covariate) == FALSE){
      cov.obs <-  covariate.mat[-which(ID > I), ]} else{
        cov.obs <- NULL}
    
    TijFN <- TijF[- c(which(IDF > I))]; TijFX <- TijF[ c(which(IDF > I))]
    IDFN <- groupFN <- IDF[- c(which(IDF > I))]; IDFX <- groupFX <- IDF[ c(which(IDF > I))]
    
    if(is.null(group) == FALSE){
      group <- group[-which(ID > I)]
      grpmember <- lapply(seq_len(I), function(ii) group[which(ID[-which(ID > I)] ==
                                                                 unique(ID[-which(ID > I)])[ii])][1])
      for(ii in 1 : I){
        groupFN[which(IDFN == unique(ID[-which(ID > I)])[ii])] <- grpmember[[ii]]
        groupFX[which(IDFX == unique(ID[which(ID > I)])[ii])] <- grpmember[[ii]]
      }}
    ID <- ID[-which(ID > I)]
    if(length(Yij) != length(Tij)){
      stop("number of observed responses does not match with number of observed time-points")}
  }
  
  ### --------------- creating design matrix for SS random effects  ------------------ ###
  
  if(Yerror == "CS"){
    
    # -------------------- Observed subjects  + Observed time-points  --------------------- #
    Z1 <- matrix(0, nrow = length(Yij), ncol = I)
    for (i in 1 : I) {
      Z1[which(ID == unique(ID)[i]), i] = 1
    }
    fZ <- cbind(Z1)
    
    # -------------------- Observed subjects  + All time-points  -------------------------- #
    Z1F <- matrix(0, nrow = length(TijFN), ncol = length(unique(IDFN)))
    for (i in 1 : I) {
      Z1F[which(IDFN == sort(unique(IDFN))[i]), i] = 1
    }
    fZF <- cbind(Z1F)
    
    if(IW != I){
      
      # ---------------------- Unobserved subjects  + All time-points  --------------------- #
      Z1FX <- matrix(0, nrow = length(TijFX), ncol = length(unique(IDFX)))
      for (i in 1 : (IW - I)) {
        Z1FX[which(IDFX == sort(unique(IDFX))[i]), i] = 1
      }
      fZFX <- cbind(Z1FX)}
  }
  
  if(Yerror == "CSG"){
    
    # -------------------- Observed subjects  + Observed time-points  --------------------- #
    Z1 = matrix(0, nrow = length(Yij), ncol = I)
    Z2 = matrix(0, nrow = length(group), ncol = G)
    for (i in 1 : I){
      Z1[which(ID == unique(ID)[i]), i] = 1
    }
    for (g in 1 : G){
      Z2[which(group == unique(group)[g]), unique(group)[g]] = 1
    }
    fZ <- cbind(Z1, Z2)
    
    # -------------------- Observed subjects  + All time-points  -------------------------- #
    Z1F <- matrix(0, nrow = length(TijFN), ncol = length(unique(IDFN)))
    Z2F <- matrix(0, nrow = length(TijFN), ncol = G)
    for (i in 1 : I) {
      Z1F[which(IDFN == unique(IDFN)[i]), i] = 1
    }
    for (g in 1 : G){
      Z2F[which(groupFN == unique(groupFN)[g]), unique(groupFN)[g]] = 1
    }
    fZF <- cbind(Z1F, Z2F)
    
    if(IW != I){
      if(length(unique(groupFX)) != G){
        stop("CAUTION New subjects are not classified into all groups. We recommend using I = IW or
             different covaraince structure.")}
      # ---------------------- Unobserved subjects  + All time-points  --------------------- #
      Z1FX <- matrix(0, nrow = length(TijFX), ncol = length(unique(IDFX)))
      Z2FX <- matrix(0, nrow = length(groupFX), ncol = G)
      for (i in 1 : (IW - I)) {
        Z1FX[which(IDFX == sort(unique(IDFX))[i]), i] = 1
      }
      for(g in 1 : G){
        Z2FX[which(groupFX == unique(groupFX)[g]), unique(groupFN)[g]] = 1
      }
      fZFX <- cbind(Z1FX, Z2FX)
      }
  }
  
  if(Yerror == "IS"){
    
    # -------------------- Observed subjects  + Observed time-points  --------------------- #
    Z1 = matrix(0, nrow = length(Yij), ncol = length(unique(ID)))
    Z2 = matrix(0, nrow = length(Yij), ncol = length(unique(ID)))
    for(i in 1 : I){
      Z1[which(ID == unique(ID)[i]), i] = 1
      Z2[which(ID == unique(ID)[i]), i] = Tij[which(ID == unique(ID)[i])]
    }
    fZ <- cbind(Z1, Z2)
    
    # -------------------- Observed subjects  + All time-points  -------------------------- #
    Z1F <- matrix(0, nrow = length(TijFN), ncol = length(unique(IDFN)))
    Z2F <- matrix(0, nrow = length(TijFN), ncol = length(unique(IDFN)))
    
    for (i in 1 : I) {
      Z1F[which(IDFN == unique(IDFN)[i]), i] = 1
      Z2F[which(IDFN == unique(IDFN)[i]), i] = TijFN[which(IDFN == unique(IDFN)[i])]
    }
    fZF <- cbind(Z1F, Z2F)
    
    if(IW != I){
      
      # ---------------------- Unobserved subjects  + All time-points  --------------------- #
      Z1FX <- matrix(0, nrow = length(TijFX), ncol = length(unique(IDFX)))
      Z2FX <- matrix(0, nrow = length(TijFX), ncol = length(unique(IDFX)))
      for (i in 1 : (IW - I)) {
        Z1FX[which(IDFX == sort(unique(IDFX))[i]), i] = 1
        Z2FX[which(IDFX == sort(unique(IDFX))[i]), i] = TijFX[which(IDFX == sort(unique(IDFX))[i])]
      }
      fZFX <- cbind(Z1FX, Z2FX)
    }
  }
  
  ### --  creating design matrix using truncated linear splines in mixed model framework -- ###
  R <- nbf
  qtiles <- seq(0, 1, length = R)[-c(1, R)]
  knots <- quantile(TT, qtiles)
  
  # ------------------- Observed subjects  + Observed time-points  --------------------------- #
  Z0 <- matrix(as.vector(cbind(sapply(knots, function(tau) ((Tij > tau) * (Tij - tau) )))), nrow = length(Tij))
  fZ0 <- cbind(1, Tij, Z0)
  bigX <- cbind(fZ, fZ0)
  
  if(is.null(covariate) == FALSE){
    bigX <- cbind(fZ, cov.obs, fZ0)
  }
  
  # ---------------------- Observed subjects  + All time-points  --------------------------- #
  Z0F <- matrix(as.vector(cbind(sapply(knots, function(tau) ((TijFN > tau) *
                                                               (TijFN - tau) )))), nrow = length(TijFN))
  fZ0F <- cbind(1, TijFN, Z0F)
  bigXF <- cbind(fZF, fZ0F)
  
  if(is.null(covariate) == FALSE && covariate.type == "Constant"){
    bigXF <- cbind(fZF,  cov.obs.all[c(1 : (I * J)), ], fZ0F)
  }
  
  if(IW != I){
    
    # ---------------------- Unobserved subjects  + All time-points  ----------------------- #
    Z0FX <- matrix(as.vector(cbind(sapply(knots, function(tau) ((TijFX > tau) * (TijFX - tau) )))),
                   nrow = length(TijFX))
    fZ0FX <- cbind(1, TijFX, Z0FX)
    
    if(is.null(covariate) == TRUE || covariate.type == "Varying"){
      bigXFX <- cbind(fZ0FX)
    }
    
    if(is.null(covariate) == FALSE && covariate.type == "Constant"){
      bigXFX <- cbind(cov.obs.all[- c(1 : (I * J)), ], fZ0FX)}
    # First I*J observations correspond to I subjects
  }
  
  if(IW != I && Yerror == "CSG"){
    
    # ------------------------------ Unobserved subjects  + All time-points  --------------------------- #
    Z0FX <- matrix(as.vector(cbind(sapply(knots, function(tau) ((TijFX > tau) * (TijFX - tau) )))),
                   nrow = length(TijFX))
    fZ0FX <- cbind(1, TijFX, Z0FX)
    
    if(is.null(covariate) == TRUE){
      bigXFX <- cbind(Z2FX, fZ0FX)
    }
    if(is.null(covariate) == FALSE && covariate.type == "Varying"){
      bigXFX <- cbind(Z2FX, fZ0FX)
    }
    if(is.null(covariate) == FALSE && covariate.type == "Constant"){
      bigXFX <- cbind(Z2FX, cov.obs.all[- c(1 : (I * J)), ], fZ0FX)
      # First I*J observations correspond to I subjects
    }
  }
  
  ### - creating design matrix for K smooth time-varying scores using truncated linear splines - ###
  
  for(n in 1 : length(funcs)){
    for(k in 1 : K.hat[[n]]){
      
      # ------------------- Observed subjects  + Observed time-points  ---------------------- #
      DD <- paste("fZ",k," <- zetaw.hatN[[", n,"]][,", k,"] * fZ0", sep = "")
      DD <- eval(parse(text = DD))
      bigX <- cbind(bigX, DD)
      
      # -------------------------- Observed subjects  + All time-points  -------------------- #
      DD <- paste("fZF",k," <- zetaw.hatE[[", n,"]][,", k,"] * fZ0F", sep = "")
      DD <- eval(parse(text = DD))
      bigXF <- cbind(bigXF, DD)
      
      if(IW != I){
        # ------------------ Unobserved subjects  + All time-points  ------------------------ #
        DD <- paste("fZFX",k," <- zetaw.hatX[[", n,"]][,", k,"] * fZ0FX", sep = "")
        DD <- eval(parse(text = DD))
        bigXFX <- cbind(bigXFX, DD)
        rm(DD)
      }
    }
  }
  if(dim(bigX)[2] > dim(bigX)[1]){
    stop("Number of observations (n) is smaller than number of parameters (p)")}
  
  ### --------------  defining the terms to be penalized  ---------------------------- ###
  
  if(Yerror == "CS"){
    E <- IN <- list()
    if(is.null(covariate) == TRUE){
      E[[1]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[1]])[c(1 : I)] <- 1
      E[[2]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[2]])[c( (I + 3) : (I + 2 + R) )] <- 1
      R1 <- R
      for(n in 1 : length(funcs)){
        IN[[n]] <- list()
        for(kk in 1 : K.hat[[n]]){
          IN[[n]][[kk]] <- c( (I + 3 + R1 + (kk - 1) * R) : (I + R1 + kk * R))
        }
        R1 <-  R1 + K.hat[[n]] * R
        E[[(2 + n)]] <- diag(rep(0, dim(bigX)[2]))
        diag(E[[(2 + n)]])[unlist(IN[[n]])] <- 1
      }
    }
    if(is.null(covariate) == FALSE){
      E[[1]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[1]])[c(1 : I)] <- 1
      II <- I + ncol(cov.obs.all) # adjusted for covariate
      E[[2]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[2]])[c( (II + 3) : (II + 2 + R) )] <- 1
      R1 <- R
      for(n in 1 : length(funcs)){
        IN[[n]] <- list()
        for(kk in 1 : K.hat[[n]]){
          IN[[n]][[kk]] <- c( (II + 3 + R1 + (kk - 1) * R) : (II + R1 + kk * R))
        }
        R1 <-  R1 + K.hat[[n]] * R
        E[[(2 + n)]] <- diag(rep(0, dim(bigX)[2]))
        diag(E[[(2 + n)]])[unlist(IN[[n]])] <- 1
      }
    }
  }
  
  if(Yerror == "CSG"){
    E <- IN <- list()
    if(is.null(covariate) == TRUE){
      E[[1]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[1]])[c(1 : I)] <- 1
      E[[2]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[2]])[ (I + 1) : (I + G) ] <- 1
      E[[3]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[3]])[c((I + G + 3) : (I + G + R))] <- 1
      R1 <- R
      for(n in 1 : length(funcs)){
        IN[[n]] <- list()
        for(kk in 1 : K.hat[[n]]){
          IN[[n]][[kk]] <- c((I + G + 3 + R1 + ((kk - 1) * R)) : (I + G + R1 + (kk * R)))
        }
        R1 <-  R1 + K.hat[[n]] * R
        E[[(3 + n)]] <- diag(rep(0, dim(bigX)[2]))
        diag(E[[(3 + n)]])[unlist(IN[[n]])] <- 1
      }
    }
    if(is.null(covariate) == FALSE){
      E[[1]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[1]])[c(1 : I)] <- 1
      E[[2]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[2]])[ (I + 1) : (I + G) ] <- 1
      II <- I + G + ncol(cov.obs.all) # adjusted for covariate
      E[[3]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[3]])[c((II + 3) : ( II + R))] <- 1
      R1 <- R
      for(n in 1 : length(funcs)){
        IN[[n]] <- list()
        for(kk in 1 : K.hat[[n]]){
          IN[[n]][[kk]] <- c((II + 3 + R1 + ((kk - 1) * R)) : (II + R1 + (kk * R)))
        }
        R1 <-  R1 + K.hat[[n]] * R
        E[[(3 + n)]] <- diag(rep(0, dim(bigX)[2]))
        diag(E[[(3 + n)]])[unlist(IN[[n]])] <- 1
      }
    }
  }
  
  if(Yerror == "IS"){
    E <- IN <- list()
    if(is.null(covariate) == TRUE){
      E[[1]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[1]])[c(1 : I)] <- 1
      E[[2]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[2]])[ (I + 1) : (2 * I) ] <- 1
      E[[3]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[3]])[c(((2 * I) + 3) : ((2 * I) + R))] <- 1
      R1 <- R
      IN <- list()
      for(n in 1 : length(funcs)){
        IN[[n]] <- list()
        for(kk in 1 : K.hat[[n]]){
          IN[[n]][[kk]] <- c(((2 * I) + 3 + R1 + ((kk - 1) * R)) : ((2 * I) + R1 + (kk * R)))
        }
        R1 <-  R1 + K.hat[[n]] * R
        E[[(3 + n)]] <- diag(rep(0, dim(bigX)[2]))
        diag(E[[(3 + n)]])[unlist(IN[[n]])] <- 1
      }
    }
    if(is.null(covariate) == FALSE){
      E[[1]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[1]])[c(1 : I)] <- 1
      E[[2]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[2]])[ (I + 1) : (2 * I) ] <- 1
      II <- 2 * I + ncol(cov.obs.all) # adjusted for covariate
      E[[3]] <- diag(rep(0, dim(bigX)[2]))
      diag(E[[3]])[c((II + 3) : ( II + R))] <- 1
      R1 <- R
      for(n in 1 : length(funcs)){
        IN[[n]] <- list()
        for(kk in 1 : K.hat[[n]]){
          IN[[n]][[kk]] <- c((II + 3 + R1 + ((kk - 1) * R)) : (II + R1 + (kk * R)))
        }
        R1 <-  R1 + K.hat[[n]] * R
        E[[(3 + n)]] <- diag(rep(0, dim(bigX)[2]))
        diag(E[[(3 + n)]])[unlist(IN[[n]])] <- 1
      }
    }
  }
  
  ### --------------------------------  fitting model  ---------------------------------- ###
  
  time <- system.time(applygam <- bam(Yij ~ bigX - 1, paraPen = list(bigX = E), method = method))[3]
  
  ### ---- prediction for observed subject corresponding to its observed time points ---- ###
  
  coefs = applygam$coef
  pred <- as.vector(as.matrix(bigX[, 1 : length(coefs)]) %*% coefs )
  pred_err <- sqrt(mean(as.vector(do.call(rbind, lapply(seq_len(length(unique(ID))), function(hh)
    mean((Yij[which(ID == unique(ID)[hh])] - pred[which(ID == unique(ID)[hh])]) ^ 2))))))
  
  ### -------------- prediction of full trajectory for observed subjects ---------------- ###
  
  if(Yerror == "CS"){
    I1 <- I
  }
  if(Yerror == "CSG"){
    I1 <- I + G
  }
  if(Yerror == "IS"){
    I1 <- 2 * I
  }
  if(is.null(covariate) == FALSE){
    I2 <- I1 + ncol(cov.obs.all)
    cov.effect <- coefs[c((I1 + 1) : I2)]
  }else{
    cov.effect <- NULL
    I2 <- I1
  }
  if(is.null(covariate) == FALSE && covariate.type == "Varying"){
    NY.pred <- as.vector(as.matrix(bigXF) %*% coefs[-c((I1 + 1) : I2)])
  }else{
    NY.pred <- as.vector(as.matrix(bigXF) %*% coefs)
  }
  
  ### ------------------ prediction of full rajectory for unobserved subjects -------------- ###
  
  if(IW != I && Yerror == "CSG"){
    if(is.null(covariate) == FALSE && covariate.type == "Varying"){
      NY.pred.X <- as.vector(as.matrix(bigXFX) %*% c(coefs[c((I + 1) : (I + G))], coefs[- c(1 : I2)]))
      # adjusting the block effect
      if(sum(is.na(NY.pred.X)) != 0) stop("Problem in creating design matrix")
    } else{
      NY.pred.X <- as.vector(as.matrix(bigXFX) %*% c(coefs[c((I + 1) : (I + G))], coefs[- c(1 : I1)]))
    }
  }
  if(IW != I && Yerror != "CSG"){
    if(is.null(covariate) == FALSE && covariate.type == "Varying"){
      NY.pred.X <- as.vector(as.matrix(bigXFX) %*% coefs[- c(1 : I2)] )
      if(sum(is.na(NY.pred.X)) != 0) stop("Problem in creating design matrix")
    }else{
      NY.pred.X <- as.vector(as.matrix(bigXFX) %*% coefs[- c(1 : I1)] )
    }
  }
  if(IW == I){
    NY.pred.X <- NULL      # not available
  }
  
  ### ----------------------------- Model adequacy (Ad-hoc) ---------------------------- ###
  
  AIC <- AIC(applygam)
  BIC <- BIC(applygam)
  Rsq <- summary(applygam)$r.sq
  dev <- summary(applygam)$dev.expl
  model_adeq <- c(AIC, BIC, Rsq, dev)
  names(model_adeq) <- c("AIC", "BIC", "R-square", "deviance explainced")
  
  ### -------------------------- estimation & prediction ------------------------------ ###
  
  qtiles <- seq(0, 1, length = R)[-c(1, R)]
  knots <- quantile(TT, qtiles)
  Zt <- matrix(as.vector(cbind(sapply(knots, function(tau) ((TT > tau) * (TT - tau) ) ))), nrow = length(TT))
  fZt <- cbind(1, TT, Zt)
  
  ### ----------------- time-varying smooth intercept --------------------------------- ###
  
  ME <- qnorm(1 - alpha / 2)
  beta0 <- fZt %*% coefs[c((I2 + 1) : (I2 + R))]
  varb <- (as.matrix(fZt)) %*%  applygam$Vp[c((I2 + 1) : (I2 + R)),
                                            c((I2 + 1) : (I2 + R))] %*% t(as.matrix(fZt))
  Bounds0 <-   cbind(beta0 - ME * sqrt(diag(varb)), beta0 + ME * sqrt(diag(varb)))
  
  ### ------------------- time-varying smooth coefficient ----------------------------- ###
  
  beta <- IN <- varBeta <- varBetaH <- Bounds <- list(); R1 <- R
  for(n in 1 : length(funcs)){
    
    IN[[n]] <-  beta[[n]] <- varBeta[[n]] <- varBetaH[[n]] <- Bounds[[n]] <- list()
    
    for(jj in 1 : K.hat[[n]]){
      IN[[n]][[jj]] <- c( (I2 + 1 + R1 + (jj - 1) * R) : (I2 + R1 + jj * R))
      varBeta[[n]][[jj]] <- applygam$Vp[ unlist(IN[[n]][[jj]]), unlist(IN[[n]][[jj]])]
      beta[[n]][[jj]] <- fZt %*% coefs[IN[[n]][[jj]]]
      varBetaH[[n]][[jj]] <- (as.matrix(fZt)) %*% varBeta[[n]][[jj]] %*% t(as.matrix(fZt))
      Bounds[[n]][[jj]] = cbind(beta[[n]][[jj]] - ME * (sqrt(diag(varBetaH[[n]][[jj]]))),
                                beta[[n]][[jj]] + ME * (sqrt(diag(varBetaH[[n]][[jj]]))))
    }
    R1 <-  R1 + K.hat[[n]] * R
  }
  
  ### ----------------------------- random effects --------------------------------- ###
  
  if (Yerror == "CS"){
    rand_int <- coefs[c(1 : I)]
    rand_slp <- NULL
    rand_grp <- NULL}
  if (Yerror == "CSG"){
    rand_int <- coefs[c(1 : I)]
    rand_slp <- NULL
    rand_grp <- coefs[c((I + 1) : (I + G))]}
  if (Yerror == "IS"){
    rand_int <- coefs[c(1 : I)]
    rand_grp <- NULL
    rand_slp <- coefs[c((I + 1) : (2 * I))]}
  
  ### -------------------------- Functional coefficient ----------------------------- ###
  
  gammaE <- list()
  for(n in 1 : length(funcs)){
    allb <- as.matrix(do.call(cbind, lapply(seq_len(K.hat[[n]]), function(jj) beta[[n]][[jj]])))
    gammaE[[n]] <- phi.hat[[n]] %*% t(allb)
  }
  
  ### --------------------------- prediction band ---------------------------------- ###
  
  if(pred.interval == TRUE){
    
    # ------------------- Observed subjects  + All time-points  ------------------------ #
    if(is.null(covariate) == FALSE && covariate.type == "Varying"){
      NY.pred <- as.vector(as.matrix(bigXF) %*% coefs[-c ((I1 + 1) : I2)])
      varYF <- bigXF %*% applygam$Vp[- c((I1 + 1) : I2), - c((I1 + 1) : I2)] %*%  t(bigXF) +
        diag(applygam$reml.scale, dim(bigXF)[1])
    }else{
      NY.pred <- as.vector(as.matrix(bigXF) %*% coefs)
      varYF <- bigXF %*% applygam$Vp %*%  t(bigXF) +  diag(applygam$reml.scale, dim(bigXF)[1])
    }
    boundYF <- cbind(NY.pred - ME * sqrt(diag(varYF)), NY.pred + ME * sqrt(diag(varYF)))
    
    if(IW != I && Yerror == "CS"){
      # ---------------------- Unobserved subjects  + All time-points  ------------------ #
      if(is.null(covariate) == FALSE && covariate.type == "Varying"){
        NY.pred.X <- as.vector(as.matrix(bigXFX) %*% coefs[- c(1 : I2)])
        varXF <- bigXFX %*% applygam$Vp[- (1 : I2), - (1 : I2)] %*% t(bigXFX) +
          gam.vcomp(applygam)[1] ^ 2 * (fZFX  %*% t(fZFX)) + diag(applygam$reml.scale, dim(bigXFX)[1])
      }else{
        NY.pred.X <- as.vector(as.matrix(bigXFX) %*% coefs[- c(1 : I1)])
        varXF <- bigXFX %*% applygam$Vp[- (1 : I1), - (1 : I1)] %*% t(bigXFX) +
          gam.vcomp(applygam)[1] ^ 2 * (fZFX  %*% t(fZFX)) +
          diag(applygam$reml.scale, dim(bigXFX)[1])
      }
      boundXF <- cbind(NY.pred.X - ME * sqrt(diag(varXF)),  NY.pred.X + ME * sqrt(diag(varXF)))
    }
    if(IW != I && Yerror == "IS"){
      # ------------------ Unobserved subjects  + All time-points  --------------------------- #
      if(is.null(covariate) == FALSE && covariate.type == "Varying"){
        NY.pred.X <- as.vector(as.matrix(bigXFX) %*% coefs[-c(1 : I2)])
        varXF <- bigXFX %*% applygam$Vp[- (1 : I2), - (1 : I2)] %*% t(bigXFX) +
          gam.vcomp(applygam)[1] ^ 2 * (Z1FX  %*% t( Z1FX )) + gam.vcomp(applygam)[2] ^ 2 *
          (Z2FX  %*% t( Z2FX )) + diag(applygam$reml.scale, dim(bigXFX)[1])
      }else{
        NY.pred.X <- as.vector(as.matrix(bigXFX) %*% coefs[- c(1 : I1)])
        varXF <- bigXFX %*% applygam$Vp[- (1 : I1), - (1 : I1)] %*% t(bigXFX) +
          gam.vcomp(applygam)[1] ^ 2 * (Z1FX  %*% t(Z1FX)) +
          gam.vcomp(applygam)[2] ^ 2 * (Z2FX  %*% t(Z2FX)) +
          diag(applygam$reml.scale, dim(bigXFX)[1])
      }
      boundXF <- cbind(NY.pred.X - ME * sqrt(diag(varXF)),  NY.pred.X + ME * sqrt(diag(varXF)))
    }
    if(IW != I && Yerror == "CSG"){
      # ------------------------------ Unobserved subjects  + All time-points  --------------------------- #
      if(is.null(covariate) == FALSE && covariate.type == "Varying"){
        NY.pred.X <- as.vector(as.matrix(bigXFX) %*%
                                 c(coefs[c((I + 1) : (I + G))], coefs[- c(1 : I2)]))
        varXF <- bigXFX %*% applygam$Vp[-c((1 : I), ((I + G + 1) : ((I + G + ncol(cov.obs))))),
                                        - c((1 : I), ((I + G + 1) : ((I + G + ncol(cov.obs)))))] %*% t(bigXFX) +
          gam.vcomp(applygam)[1] ^ 2 * (Z1FX  %*% t(Z1FX)) + diag(applygam$reml.scale, dim(bigXFX)[1])
      }else{
        NY.pred.X <- as.vector(as.matrix(bigXFX) %*% coefs[- (1 : I)])
        varXF <- bigXFX %*% applygam$Vp[- (1 : I), - (1 : I)] %*% t(bigXFX) +
          gam.vcomp(applygam)[1] ^ 2 * (Z1FX  %*% t(Z1FX)) + diag(applygam$reml.scale, dim(bigXFX)[1])
      }
      boundXF <- cbind(NY.pred.X - ME * sqrt(diag(varXF)),  NY.pred.X + ME * sqrt(diag(varXF)))
    }
    
    if(IW == I){
      boundXF <- 9999999} # Not available
    if(pred.interval == FALSE){
      boundYF <- boundXF <- 9999999} # Not available
  }
  
  ### -------------------------------- plot ------------------------------------------ ###
  if(plot == TRUE){
    # -------------------------- Random effects ----------------------------- #
    if(Yerror == "CS"){
      par(mfrow = c(1, 1))
      Estimates <- as.vector(c(rand_int))
      Terms <- as.character(c(rep("intercept", I)))
      mrg <- data.frame(as.matrix(as.data.frame(cbind(Estimates, Terms))))
      mrg$Estimates <- as.numeric(mrg$Estimates)
      mrg$Terms <- as.factor(mrg$Terms)
      mrg$Estimates <- Estimates
      tb0 <- expression(""~hat(b)[i0])
      eff <- ggplot(mrg, aes(x = Terms, y = Estimates)) + theme_bw() + theme(text = element_text(size = 17)) +
        geom_boxplot(outlier.shape = NA) + geom_jitter(position = position_jitter(width = .1, height = 0)) +
        annotate("text", x = 1, y = 3.5, parse = T, label = as.character(tb0), size = 6)
      print(eff)
    }
    if(Yerror == "CSG"){
      par(mfrow = c(2, 1))
      Estimates <- as.vector(c(rand_grp, rand_int))
      Terms <- as.character(c(rep("block", G), rep("intercept", I)))
      mrg <- data.frame(as.matrix(as.data.frame(cbind(Estimates, Terms))))
      mrg$Estimates <- as.numeric(mrg$Estimates)
      mrg$Terms <- as.factor(mrg$Terms)
      mrg$Estimates <- Estimates
      tb1 <- expression(""~hat(b)[i0])
      tb0 <- expression(""~hat(g)[k])
      eff <- ggplot(mrg, aes(x = Terms, y = Estimates)) + theme_bw() + theme(text = element_text(size = 17)) +
        geom_boxplot(outlier.shape = NA) + geom_jitter(position = position_jitter(width =.1, height = 0)) +
        annotate("text", x = 1, y = 3.5, parse = T, label = as.character(tb0), size = 6) +
        annotate("text", x = 2, y = 3.5, parse = T, label = as.character(tb1), size = 6)
      print(eff)
    }
    if(Yerror == "IS"){
      par(mfrow = c(2, 1))
      Estimates <- as.vector(c(rand_int, rand_slp))
      Terms <- as.character(c(rep("intercept", I), rep("slope", I)))
      mrg <- data.frame(as.matrix(as.data.frame(cbind(Estimates, Terms))))
      mrg$Estimates <- as.numeric(mrg$Estimates)
      mrg$Terms <- as.factor(mrg$Terms)
      mrg$Estimates <- Estimates
      tb0 <- expression(""~hat(b)[i0])
      tb1 <- expression(""~hat(b)[i1])
      eff <- ggplot(mrg, aes(x = Terms, y = Estimates)) + theme_bw() + theme(text = element_text(size = 17)) +
        geom_boxplot(outlier.shape = NA) + geom_jitter(position = position_jitter(width =.1, height = 0)) +
        annotate("text", x = 1, y = 3.5, parse = T, label = as.character(tb0), size = 6) +
        annotate("text", x = 2, y = 3.5, parse = T, label = as.character(tb1), size = 6)
      print(eff)
    }
    
    
    # -------------------- Estimated smooth coefficients ---------------------- #
    for(n in 1 : length(gammaE)){
      gamma <- gammaE[[n]]
      Functional_hours <- paste0("s_", 1 : SS)
      Longitudinal_time <- paste0("t_", 1 : J)
      sq <- Functional_hours[seq(1,length(Functional_hours), 10)]
      sq2 <- Longitudinal_time[seq(1,length(Longitudinal_time), 5)]
      Longitudinal_time <-  paste0("t_", 1 : J)
      rownames(gamma) <- Functional_hours[1 : dim(gamma)[1]]
      colnames(gamma) <- Longitudinal_time[1 : dim(gamma)[2]]
      longData <- melt(gamma)
      names(longData) <- c("Functional_hours", "Longitudinal_time",  "value")
      longData$Longitudinal_time <- factor(longData$Longitudinal_time)
      longData$Functional_hours <- factor(longData$Functional_hours)
      myPalette <- colorRampPalette(brewer.pal(11, "Spectral"), space = "rgb", bias = 1)
      zp1 <- ggplot(longData, aes(y = Functional_hours, x = Longitudinal_time, fill = value))
      zp1 <- zp1 + theme(text = element_text(size = 15), axis.text.x =
                           element_text(size = 15, angle = 0), axis.text.y = element_text(size = 15, angle = 0))
      zp1 <- zp1 + geom_tile()
      zp1 <- zp1 + scale_fill_gradientn(colours = myPalette(200))
      zp1 <- zp1 + scale_y_discrete(breaks = sq)
      zp1 <- zp1 + scale_x_discrete(breaks = sq2)
      print(zp1)
    }
    
    # ---------- full trajectory of observed subject ---------- #
    
    if(pred.interval == TRUE){
      par(mfrow = c(2, 2))
      
      if(is.null(subj.id) == TRUE){subj.id <- sample(unique(IDFN), 1, replace = FALSE)}
      
      for(ii in 1 : length(subj.id)){
        
        plot(TT, NY.pred[which(IDFN == subj.id[ii])], type = "b", lty = 1, col = "black", lwd = 2,
             ylab = "", xlab = "Time", main = paste0("Prediction for observed subject ", subj.id[ii], ""))
        
        polygon(x = c(TT, rev(TT)), y = c(boundYF[which(IDFN == subj.id[ii]), 1],
                                          rev(boundYF[which(IDFN == subj.id[ii]), 2])), col = 'grey80', border = NA)
        
        lines(TT, NY.pred[which(IDFN == subj.id[ii])], type = "b", lty = 1, col = "black", lwd = 2)
      }
      
      if(IW != I){
        if(is.null(subj.id.X) == TRUE){subj.id.X <- sample(unique(IDFX), 1, replace = FALSE)}
        
        for(ii in 1 : length(subj.id.X)){
          
          plot(TT, NY.pred.X[which(IDFX == subj.id.X[ii])], type = "b", lty = 1, col = "black", lwd = 2,
               ylab = "", xlab = "Time", main = paste0("Prediction for new subject ", subj.id.X[ii], ""))
          
          polygon(x = c(TT, rev(TT)), y = c(boundXF[which(IDFX == subj.id.X[ii]), 1],
                                            rev(boundXF[which(IDFX == subj.id.X[ii]), 2])), col = 'grey80', border = NA)
          
          lines(TT, NY.pred.X[which(IDFX == subj.id.X[ii])], type = "b", lty = 1, col = "black", lwd = 2)}
      }}}
  
  ### -------------------------------- output ------------------------------------------ ###
  
  return = list(fit = applygam,
                model_adequacy = model_adeq,
                fitted_vals = pred,
                full_fitted_vals_obs = NY.pred,
                full_fitted_vals_unobs = NY.pred.X,
                error = pred_err,
                npc = K.hat,
                phi = phi.hat,
                evalues = eigenvalues,
                scores_hat = zetaw.hat,
                scores_hat_traj = zetaw.hatF,
                scores_pseudo = zetaw.hatN,
                
                ranef_intercept = rand_int,
                ranef_slope = rand_slp,
                ranef_group =  rand_grp,
                Mean_X_obs  = fbps.fit$Yhat,
                
                gamma = gammaE,
                covariate_effect = cov.effect,
                beta = beta,
                beta0 = beta0,
                Bounds =  Bounds,
                BoundYF = boundYF,
                BoundXF = boundXF,
                mFPCA = covsmooth,
                sFPCA = fit2)
}
